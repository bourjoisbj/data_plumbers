
########### TWITTER DATA INGESTION USING FLUME #### CONFIGURATION #############

## Check this link for details information
https://www.tutorialspoint.com/apache_flume/fetching_twitter_data.htm

# Ingestion is done with keyword “evanston”

# Run Hadoop if it is not running yet
start-yarn.sh
start-dfs.sh

# Check if Hadoop is running properly
jps

cd opt/flume-1.8.0/conf
ls
gedit flume-env.sh

# Add the following command to the file and save
export CLASSPATH=$CLASSPATH:/FLUME_HOME/lib/* 

# Create a copy of the conf.proporties for twitter
cp flume-conf.properties.template flume-conf-twitter.properties
gedit flume-conf-twitter.properties

# Type the confiurations below in the file and save

    ## TWITTER CONFIGURATION 

    # Naming the components on the current agent. 
    TwitterAgent.sources = Twitter 
    TwitterAgent.channels = MemChannel 
    TwitterAgent.sinks = HDFS
    
    # Describing/Configuring the source 
    TwitterAgent.sources.Twitter.type = org.apache.flume.source.twitter.TwitterSource
    TwitterAgent.sources.Twitter.consumerKey = Your AOuth consumer key
    TwitterAgent.sources.Twitter.consumerSecret = Your AOuth consumer secret key
    TwitterAgent.sources.Twitter.accessToken = Your AOuth consumer key access token
    TwitterAgent.sources.Twitter.accessTokenSecret = Your AOuth consumer key access token secret
    TwitterAgent.sources.Twitter.keywords = evanston
    TwitterAgent.sources.Twitter.language = en   

    # Describing/Configuring the sink 

    TwitterAgent.sinks.HDFS.type = hdfs 
    TwitterAgent.sinks.HDFS.hdfs.path = /twitter_data/
    TwitterAgent.sinks.HDFS.hdfs.fileType = DataStream 
    TwitterAgent.sinks.HDFS.hdfs.writeFormat = Text 
    TwitterAgent.sinks.HDFS.hdfs.batchSize = 1000
    TwitterAgent.sinks.HDFS.hdfs.rollSize = 0 
    TwitterAgent.sinks.HDFS.hdfs.rollCount = 10000 
    
    # Describing/Configuring the channel 
    TwitterAgent.channels.MemChannel.type = memory 
    TwitterAgent.channels.MemChannel.capacity = 10000 
    TwitterAgent.channels.MemChannel.transactionCapacity = 100
    
    # Binding the source and sink to the channel 
    TwitterAgent.sources.Twitter.channels = MemChannel
    TwitterAgent.sinks.HDFS.channel = MemChannel

# Create a folder in HDFS to receive the data
# But this is not necessary because the file get created in case you don't, since it is set in the flume configuration file.
hdfs dfs -mkdir /twitter_data

# Begin ingestion with flume by running the following command
# Make sure hdfs is running
start-all.sh
flume-ng agent --name TwitterAgent --conf-file home/opt/flume-1.8.0/conf/flume-conf-twitter.properties -Dflume.root.logger=INFO,console

# Check storage content
hdfs dfs -ls /twitter_data
# This will give you the path of the storage file 
# The path will look like this: twitter_data/FlumeData.someNumber.tmp

# Visualization of stored data
hdfs dfs -cat /twitter_data/FlumeData.someNumber.tmp

