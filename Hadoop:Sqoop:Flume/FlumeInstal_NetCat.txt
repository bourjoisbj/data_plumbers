
## FLUME

## INSTALL FLUME

# doc for the properties: https://data-flair.training/blogs/flume-source/

cd opt
wget http://archive.apache.org/dist/flume/1.8.0/apache-flume-1.8.0-bin.tar.gz
tar zxvf apache-flume-1.8.0-bin.tar.gz 
rm apache-flume-1.8.0-bin.tar.gz
mv apache-flume-1.8.0-bin/ flume-1.8.0
cd flume-1.8.0/

# Get path
pwd

cd
gedit .bash_profile

# Type or paste in file
## FLUME HOME
export FLUME_HOME=/home/fieldemploye/opt/flume-1.8.0
export PATH=$PATH:$FLUME_HOME/bin

# Source
source .bash_profile

# Check flume version
flume-ng version 



# FLUME CONFIGURATION

cd Desktop/opt/flume-1.8.0/conf/
ls
cp flume-conf.properties.template flume-conf1.properties
ls
gedit flume-conf1.properties

# Name the components
plumber.sources = file1
plumber.sinks = hdfs1
plumber.channels = mem

# Configure Source
plumber.sources.file1.type = spooldir
plumber.sources.file1.spoolDir = /home/fieldemploye/opt/flumeTest1
plumber.sources.file1.fileHeader = true

# Configure Channel
plumber.channels.mem.type = memory
plumber.channels.mem.capacity = 1000
plumber.channels.mem.transactionCapacity = 100

# Configure Sink
plumber.sinks.hdfs1.type = hdfs
plumber.sinks.hdfs1.hdfs.path = /flume01
plumber.sinks.hdfs1.hdfs.fileType = DataStream

# Configure connection
plumber.sources.file1.channels = mem
plumber.sinks.hdfs1.channel = mem

cd Desktop
mkdir flumeTest1
cd flumeTest1
gedit flumetest
# Type anything for content and save

# Get the path
pwd
# Paste inside flume-conf1.properties

cd

# Check if Hadoop is running
jps

hdfs dfs -ls /
hdfs dfs -mkdir /flume01
hdfs dfs -ls /

pwd
# Copy and paste into flume-conf1.properties 

# Start Ingestion with Flume
flume-ng agent -n plumber -c conf -f ~/opt/flume-1.8.0/conf/flume-conf1.properties -Dflume.root.logger=DEBUG,console

# I encountered issues at this point
# The following link was helpful solving the errors issues encountered
# https://stackoverflow.com/questions/58688470/flume-sink-to-hdfs-error-java-lang-nosuchmethoderror-com-google-common-base-pr




## FLUME AND NETCAT

 cd $FLUME_HOME
 cd lib/
 sudo rm guava-11.0.2.jar

 cd opt/flume-1.8.0/conf/
 ls
 cp flume-conf.properties.template flume-conf2.properties
 ls
 gedit flume-conf2.properties
    
    agent.sources = netcat
    agent.channels = mem
    agent.sinks = hadoop


    # Define sources type
    agent.sources.netcat.type = netcat
    agent.sources.netcat.bind= localhost
    agent.sources.netcat.port= 44444

    # Define channels
    agent.channels.mem.type = memory
    agent.channels.mem.capacity= 1000
    agent.channels.mem.transactionCapacity= 100

    # Define sinks type
    agent.sinks.hadoop.type = hdfs
    agent.sinks.hadoop.hdfs.path= /flumenetcat
    agent.sinks.hadoop.hdfs.roll.Interval= 10
    agent.sinks.hadoop.hdfs.writeFormat= Text
    agent.sinks.hadoop.hdfs.filetype= DataStream

    # Binding sources and sinking to channels
    agent.sources.netcat.channels= mem
    agent.sinks.hadoop.channel= mem

 hdfs dfs -ls /
 hdfs dfs -mkdir /flumeNetcat

# Start flume-Netcat

 flume-ng agent --name agent --conf-file conf/flume-conf2.properties -Dflume.root.logger=INFO,console

## look when the command is running the ip address 

# Open new terminal - type command below to send message to hdfs

 nc 127.0.0.1 44444

#  New file should be on hdfs dfs -ls /flumeNetcat 

